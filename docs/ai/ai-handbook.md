# AI Handbook

## Как отладить матчинговую выдачу
1. **Соберите контекст запроса**: входные фичи, сегмент пользователя, включённые feature flags.
2. **Проверьте пайплайн**: скоринг модели, нормализация, бизнес-правила пост-фильтра, explainability-факторы.
3. **Сравните с эталонами**: используйте offline-logs и baseline выдачу, смотрите метрики precision@3, fill-rate.
4. **Диагностируйте данные**: убедитесь, что профили не устарели, нет ли пустых категорий или заблокированных исполнителей.
5. **Результат**: создайте debug-отчёт с ID запроса, top факторов и найденными аномалиями.

## Как развернуть/обновить модель
1. Подготовьте модельный артефакт в registry (версия, дата, SHA).
2. Прогоните unit + offline тесты, затем staging A/B с shadow-логированием.
3. Обновите feature flags и конфигурацию inference-сервиса (CPU/GPU, автоскейлинг).
4. Пропишите версию в `model-health-dashboard` и уведомите on-call.
5. После rollout — заполните rollout-report и приложите latency/качество.

## Как оценить эксперимент и принять решение
1. Определите primary KPI (например, hire conversion, отклики) и guardrails (жалобы, latency, escrow adoption).
2. Используйте A/B-платформу: дождитесь статистической мощности, проверьте CUPED/stratified анализ.
3. Сформируйте решение: ship/iterate/rollback. Обоснуйте цифрами и качественными инсайтами.
4. Обновите roadmap и поставьте follow-up задачи.

## Как расследовать жалобу на AI
1. Возьмите ID подсказки/рекомендации и выгрузите логи (промпт, ответ, версия модели, explainability-факторы).
2. Сверьте с Responsible AI Policy: есть ли нарушения (контакты, вред, дисклеймеры).
3. Посмотрите UX-контекст: локаль, состояние «AI отключён», были ли нажатия «Пожаловаться».
4. Подготовьте ответ пользователю и действия (фикс промпта, блокировка модели, обновление фильтров).
5. Зафиксируйте кейс в AI Incident Tracker и отметьте статус (открыт/решён).

## Трёхфазный запуск (Stage → Prod)
1. **Shadow-mode (1 неделя)**: модель отвечает и логирует качество/latency, но подсказки скрыты от пользователей. Цель — убедиться в стабильности данных и фильтров.
2. **Dark launch 10–20%**: включаем подсказки для ограниченных сегментов, мониторим KPI и guardrails (жалобы, latency, escrow adoption) в режиме on-call.
3. **Расширение до 100%**: после выполнения целевых KPI и отсутствия нарушений guardrails постепенно увеличиваем долю до 100%, фиксируем результат в rollout report и запускаем обучение на новых данных.
